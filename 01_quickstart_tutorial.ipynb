{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaCoZu/pytorch_tutorials/blob/main/01_quickstart_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "edOmBZNsx6kW",
        "outputId": "a4612e53-8b5c-4741-8aee-de83cb20ce60"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3144ffc0faa1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    +# For tips on running notebooks in Google Colab, see\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "+# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr-TmkHkx6kX"
      },
      "source": [
        "\n",
        "[Learn the Basics](intro.html) ||\n",
        "**Quickstart** ||\n",
        "[Tensors](tensorqs_tutorial.html) ||\n",
        "[Datasets & DataLoaders](data_tutorial.html) ||\n",
        "[Transforms](transforms_tutorial.html) ||\n",
        "[Build Model](buildmodel_tutorial.html) ||\n",
        "[Autograd](autogradqs_tutorial.html) ||\n",
        "[Optimization](optimization_tutorial.html) ||\n",
        "[Save & Load Model](saveloadrun_tutorial.html)\n",
        "\n",
        "# Quickstart\n",
        "This section runs through the API for common tasks in machine learning. Refer to the links in each section to dive deeper.\n",
        "\n",
        "## Working with data\n",
        "PyTorch has two [primitives to work with data](https://pytorch.org/docs/stable/data.html):\n",
        "``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset``.\n",
        "``Dataset`` stores the samples and their corresponding labels, and ``DataLoader`` wraps an iterable around\n",
        "the ``Dataset``.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T891wIEfx6kZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK1e0B4mx6kZ"
      },
      "source": [
        "PyTorch offers domain-specific libraries such as [TorchText](https://pytorch.org/text/stable/index.html),\n",
        "[TorchVision](https://pytorch.org/vision/stable/index.html), and [TorchAudio](https://pytorch.org/audio/stable/index.html),\n",
        "all of which include datasets. For this tutorial, we  will be using a TorchVision dataset.\n",
        "\n",
        "The ``torchvision.datasets`` module contains ``Dataset`` objects for many real-world vision data like\n",
        "CIFAR, COCO ([full list here](https://pytorch.org/vision/stable/datasets.html)). In this tutorial, we\n",
        "use the FashionMNIST dataset. Every TorchVision ``Dataset`` includes two arguments: ``transform`` and\n",
        "``target_transform`` to modify the samples and labels respectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vNKO4Qux6ka",
        "outputId": "b296635c-eb14-498c-f166-71a7e53395cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 114410098.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 5823997.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 67145396.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 23964791.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIH036NNx6ka"
      },
      "source": [
        "We pass the ``Dataset`` as an argument to ``DataLoader``. This wraps an iterable over our dataset, and supports\n",
        "automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element\n",
        "in the dataloader iterable will return a batch of 64 features and labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SOO7SVJx6kb",
        "outputId": "878b9c45-b274-4c4c-f17c-276374efd122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3XCMybRx6kc"
      },
      "source": [
        "Read more about [loading data in PyTorch](data_tutorial.html).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJfXirF3x6kc"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcH9nm3x6kd"
      },
      "source": [
        "## Creating Models\n",
        "To define a neural network in PyTorch, we create a class that inherits\n",
        "from [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). We define the layers of the network\n",
        "in the ``__init__`` function and specify how data will pass through the network in the ``forward`` function. To accelerate\n",
        "operations in the neural network, we move it to the GPU or MPS if available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z37Lx9wx6ke",
        "outputId": "577e6410-7224-424e-de9d-80107e89d71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # nn.Linear layer is used for linear transformations, also known as fully connected layer or dense layer\n",
        "            nn.Linear(28*28, 512),\n",
        "            #  nn.ReLU() layer applies the Rectified Linear Unit (ReLU) activation function to introduce non-linearity.\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            # The final nn.Linear(512, 10) layer takes the output of the second layer (512-dimensional tensor) and produces\n",
        "            # a 10-dimensional tensor, which corresponds to the number of output classes (assuming this is a classification problem with 10 classes).\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# .to(device) method is used to move the model to the specified device (CPU, GPU, or MPS).\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqHYT0Fkx6ke"
      },
      "source": [
        "Read more about [building neural networks in PyTorch](buildmodel_tutorial.html).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llskSn8ox6kf"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srRRqYB-x6kf"
      },
      "source": [
        "## Optimizing the Model Parameters\n",
        "To train a model, we need a [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "and an [optimizer](https://pytorch.org/docs/stable/optim.html).\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>Explanation</summary>\n",
        "\n",
        "\n",
        "  torch.optim.SGD:<br>\n",
        "  is an optimizer in PyTorch that stands for Stochastic Gradient Descent. It is used to update the parameters of a neural network during the training process. SGD is one of the most popular optimization algorithms used in machine learning and deep learning.\n",
        "\n",
        "\n",
        "  model.parameters(): <br>\n",
        "  This part passes the parameters of the neural network model to the optimizer. The model.parameters() function returns an iterable containing all the learnable parameters of the model. These parameters are the weights and biases of the fully connected layers defined in the NeuralNetwork model.\n",
        "\n",
        "\n",
        "  lr=1e-3: <br>\n",
        "  This is the learning rate, which is a hyperparameter that controls the step size at each iteration of the optimization process. The learning rate determines how much the model parameters will be updated based on the gradients of the loss function with respect to the parameters. A small learning rate means small updates, while a large learning rate means larger updates. The value 1e-3 is a shorthand notation for 0.001.\n",
        "\n",
        "\n",
        "So, when you create the SGD optimizer as shown in the code snippet, it means you want to use Stochastic Gradient Descent to update the parameters of the model (an instance of the NeuralNetwork class) during the training process, and the learning rate is set to 0.001 (or 1e-3).\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9ccB_Jrdx6kf"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zos7x3Zrx6kg"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and\n",
        "backpropagates the prediction error to adjust the model's parameters.\n",
        "\n",
        "<details>\n",
        "  <summary> Explanation </summary>\n",
        "\n",
        "\n",
        "This code defines a function called `train`, which is used to train a neural network model using a given dataloader, loss function, and optimizer. The function performs a single training epoch, which means it processes all the batches from the dataloader once to update the model's parameters.\n",
        "\n",
        "\n",
        "Let's go through the code step by step:\n",
        "\n",
        "\n",
        "1. `def train(dataloader, model, loss_fn, optimizer):`\n",
        "   - The function `train` is defined, which takes four arguments: `dataloader`, `model`, `loss_fn`, and `optimizer`. These are the components needed for training the model.\n",
        "\n",
        "2. `size = len(dataloader.dataset)`\n",
        "   - The `size` variable is set to the total number of samples in the dataset that the dataloader loads. This is used to track the progress of training and to calculate the percentage of data processed.\n",
        "\n",
        "3. `model.train()`\n",
        "   - The `model.train()` call sets the model in training mode. This is necessary because some layers, such as dropout and batch normalization, behave differently during training and evaluation.\n",
        "\n",
        "4. `for batch, (X, y) in enumerate(dataloader):`\n",
        "   - The function iterates over batches in the dataloader. It uses the `enumerate` function to get both the batch index (`batch`) and the data (`X` and `y`) from the dataloader.\n",
        "\n",
        "5. `X, y = X.to(device), y.to(device)`\n",
        "   - The data `X` and the corresponding labels `y` are moved to the specified device (`device` was determined earlier, e.g., \"cuda\" for GPU or \"cpu\").\n",
        "\n",
        "6. `pred = model(X)`\n",
        "   - The model is used to make predictions (`pred`) on the input data `X`.\n",
        "\n",
        "7. `loss = loss_fn(pred, y)`\n",
        "   - The loss function (`loss_fn`) is applied to calculate the prediction error between the predicted values (`pred`) and the actual labels (`y`).\n",
        "\n",
        "8. `loss.backward()`\n",
        "   - Backpropagation is performed to compute the gradients of the loss with respect to the model's parameters.\n",
        "\n",
        "9. `optimizer.step()`\n",
        "   - The optimizer updates the model's parameters based on the computed gradients. This is the step where the model learns from the training data.\n",
        "\n",
        "10. `optimizer.zero_grad()`\n",
        "   - The gradients of the model's parameters are reset to zero. This step is necessary before computing the gradients for the next batch to avoid accumulation of gradients from previous batches.\n",
        "\n",
        "11. `if batch % 100 == 0: ...`\n",
        "   - This block of code prints the training progress every 100 batches. It displays the current loss and the number of processed samples out of the total dataset size.\n",
        "\n",
        "In summary, the `train` function takes care of a single training epoch for a given model using a dataloader, loss function, and optimizer. It iterates through batches, makes predictions, calculates the loss, performs backpropagation, updates the model's parameters, and prints the training progress at regular intervals. The entire process is repeated for each epoch to train the model effectively.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rR_TeRNqx6kg"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uBUHuiinEDbB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjYGdPPkx6kg"
      },
      "source": [
        "We also check the model's performance against the test dataset to ensure it is learning.\n",
        "\n",
        "<details>\n",
        "  <summary>Explanation</summary>\n",
        "  This code defines a function called `test`, which is used to evaluate the performance of a trained neural network model using a given dataloader and loss function. The function computes the test accuracy and average test loss over the entire test dataset.\n",
        "\n",
        "Let's break down the code step by step:\n",
        "\n",
        "1. `def test(dataloader, model, loss_fn):`\n",
        "   - The function `test` is defined, which takes three arguments: `dataloader`, `model`, and `loss_fn`. These are the components needed for evaluating the model's performance on the test dataset.\n",
        "\n",
        "2. `size = len(dataloader.dataset)`\n",
        "   - The `size` variable is set to the total number of samples in the test dataset that the dataloader loads. This is used to calculate the test accuracy later.\n",
        "\n",
        "3. `num_batches = len(dataloader)`\n",
        "   - The `num_batches` variable is set to the total number of batches in the dataloader. This is used to calculate the average test loss later.\n",
        "\n",
        "4. `model.eval()`\n",
        "   - The `model.eval()` call sets the model in evaluation mode. This is necessary because some layers, such as dropout and batch normalization, behave differently during training and evaluation. Setting the model in evaluation mode disables dropout and batch normalization layers.\n",
        "\n",
        "5. `test_loss, correct = 0, 0`\n",
        "   - Two variables are initialized to keep track of the cumulative test loss and the number of correctly classified samples in the test dataset.\n",
        "\n",
        "6. `with torch.no_grad():`\n",
        "   - The code inside this block ensures that no gradients are computed during the evaluation. This is done to save memory and computation since gradients are not needed during the evaluation phase.\n",
        "\n",
        "7. `for X, y in dataloader:`\n",
        "   - The function iterates over batches in the dataloader, where `X` represents the input data, and `y` represents the corresponding labels.\n",
        "\n",
        "8. `X, y = X.to(device), y.to(device)`\n",
        "   - The data `X` and the corresponding labels `y` are moved to the specified device (`device` was determined earlier, e.g., \"cuda\" for GPU or \"cpu\").\n",
        "\n",
        "9. `pred = model(X)`\n",
        "   - The model is used to make predictions (`pred`) on the input data `X`.\n",
        "\n",
        "10. `test_loss += loss_fn(pred, y).item()`\n",
        "    - The loss function (`loss_fn`) is applied to calculate the test loss between the predicted values (`pred`) and the actual labels (`y`). The test loss is accumulated for all batches.\n",
        "\n",
        "11. `correct += (pred.argmax(1) == y).type(torch.float).sum().item()`\n",
        "    - The code compares the model's predicted class (obtained using `pred.argmax(1)`) to the true class labels (`y`). It counts the number of correctly classified samples in the batch and accumulates the count for all batches.\n",
        "\n",
        "12. `test_loss /= num_batches`\n",
        "    - The accumulated test loss is divided by the total number of batches (`num_batches`) to obtain the average test loss.\n",
        "\n",
        "13. `correct /= size`\n",
        "    - The accumulated count of correctly classified samples is divided by the total number of samples in the test dataset (`size`) to obtain the test accuracy.\n",
        "\n",
        "14. `print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")`\n",
        "    - The function prints the test accuracy and average test loss.\n",
        "\n",
        "In summary, the `test` function evaluates the performance of a trained neural network model on the test dataset. It computes the test accuracy and average test loss by iterating over the test dataloader and making predictions using the model. The function does not update the model's parameters and is only used for evaluation purposes.\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h5W3J8xFx6kh"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oEdQC2Ax6kh"
      },
      "source": [
        "The training process is conducted over several iterations (*epochs*). During each epoch, the model learns\n",
        "parameters to make better predictions. We print the model's accuracy and loss at each epoch; we'd like to see the\n",
        "accuracy increase and the loss decrease with every epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJmK9SzVx6kh",
        "outputId": "731583d0-3b2e-4154-9f64-f4d0231c4487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.313956  [   64/60000]\n",
            "loss: 2.285758  [ 6464/60000]\n",
            "loss: 2.273672  [12864/60000]\n",
            "loss: 2.264206  [19264/60000]\n",
            "loss: 2.230599  [25664/60000]\n",
            "loss: 2.223581  [32064/60000]\n",
            "loss: 2.218231  [38464/60000]\n",
            "loss: 2.192645  [44864/60000]\n",
            "loss: 2.182539  [51264/60000]\n",
            "loss: 2.144359  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.9%, Avg loss: 2.143307 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.157951  [   64/60000]\n",
            "loss: 2.136428  [ 6464/60000]\n",
            "loss: 2.081563  [12864/60000]\n",
            "loss: 2.098812  [19264/60000]\n",
            "loss: 2.039306  [25664/60000]\n",
            "loss: 1.988308  [32064/60000]\n",
            "loss: 2.011313  [38464/60000]\n",
            "loss: 1.934308  [44864/60000]\n",
            "loss: 1.932187  [51264/60000]\n",
            "loss: 1.853156  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.0%, Avg loss: 1.857818 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.896335  [   64/60000]\n",
            "loss: 1.856865  [ 6464/60000]\n",
            "loss: 1.738919  [12864/60000]\n",
            "loss: 1.782669  [19264/60000]\n",
            "loss: 1.677593  [25664/60000]\n",
            "loss: 1.630099  [32064/60000]\n",
            "loss: 1.654149  [38464/60000]\n",
            "loss: 1.557122  [44864/60000]\n",
            "loss: 1.580174  [51264/60000]\n",
            "loss: 1.472722  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.8%, Avg loss: 1.495605 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.566459  [   64/60000]\n",
            "loss: 1.527640  [ 6464/60000]\n",
            "loss: 1.379884  [12864/60000]\n",
            "loss: 1.452546  [19264/60000]\n",
            "loss: 1.343677  [25664/60000]\n",
            "loss: 1.334232  [32064/60000]\n",
            "loss: 1.352857  [38464/60000]\n",
            "loss: 1.276306  [44864/60000]\n",
            "loss: 1.309563  [51264/60000]\n",
            "loss: 1.211969  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.6%, Avg loss: 1.241106 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.318622  [   64/60000]\n",
            "loss: 1.298357  [ 6464/60000]\n",
            "loss: 1.136837  [12864/60000]\n",
            "loss: 1.240010  [19264/60000]\n",
            "loss: 1.124975  [25664/60000]\n",
            "loss: 1.141743  [32064/60000]\n",
            "loss: 1.167687  [38464/60000]\n",
            "loss: 1.101904  [44864/60000]\n",
            "loss: 1.140586  [51264/60000]\n",
            "loss: 1.058854  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.8%, Avg loss: 1.082731 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdjLHbfZx6kh"
      },
      "source": [
        "Read more about [Training your model](optimization_tutorial.html).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jpk869zx6kh"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUSqBx5Yx6kh"
      },
      "source": [
        "## Saving Models\n",
        "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daVEYLSTx6ki",
        "outputId": "3baf6852-788e-4d0e-bb92-82c644dd378e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHHuF0A1x6ki"
      },
      "source": [
        "## Loading Models\n",
        "\n",
        "The process for loading a model includes re-creating the model structure and loading\n",
        "the state dictionary into it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfJwkKG8x6ki",
        "outputId": "7bb58f7b-2b70-44d3-f782-86fa44e15e6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u74ipH8Gx6kj"
      },
      "source": [
        "This model can now be used to make predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRJQcKyfx6kj",
        "outputId": "76a91e2c-84a0-4bee-b9ed-24d83e1de7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW8ANJ3Px6kj"
      },
      "source": [
        "Read more about [Saving & Loading your model](saveloadrun_tutorial.html).\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}